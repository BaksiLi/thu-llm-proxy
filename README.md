# THU LLM Proxy Gateway

æ¸…åå¤§æ¨¡å‹åä»£
> ä½ æ¸…æœ‰äº†è‡ªå·±çš„ DeepSeek å®ä¾‹ï¼Œä½†æ˜¯é™åˆ¶æ ¡å›­ç½‘ç™»é™†ï¼Œäºæ˜¯ä¾¿æœ‰äº†æœ¬é¡¹ç›®ã€‚  

## âœ¨ Features 
- ğŸ” Reverse proxy for campus-only LLM APIs
- ğŸš€ Stream response optimization (filter empty chunks)
- - [ ] ğŸ”’ Safety features (IP whitelist)


## âš™ï¸ Configuration
Create `.env` file:
```
PROXY_PORT=11443

HOST_ADDRESS=api.example.com

UPSTREAM_ENDPOINT=https://madmodel.cs.tsinghua.edu.cn
```

## ğŸš€ Deployment
```
# 1. Clone repository
git clone https://github.com/yourname/thu-llm-proxy
cd thu-llm-proxy

# 2. Build and start
docker-compose up -d --build

# 3. Verify
curl -v -x POST http://localhost:${PROXY_PORT}/v1/chat/completions
```

## ğŸŒ Usage
```
curl --location -X POST 'http://api.example.com:11443/v1/chat/completions' \
--header 'Content-Type: application/json' \
--header 'Authorization: Bearer <YOUR_TOKEN>' \
-d '{
  "model": "DeepSeek-R1-Distill-32B",
  "messages": [
    { "role": "user", "content": "Only Say Yes" }
  ],
  "stream": true
}'
```

## âš ï¸ Disclaimer
**For Technical Study Only ä»…ä¾›æŠ€æœ¯ç ”ç©¶**  
This project is intended for educational purposes in network programming and reverse proxy implementations. The maintainers do not encourage nor endorse bypassing institutional network policies. Use at your own risk.

## ğŸ“œ License
MIT
